{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch monai nnunet\n\nimport os\nimport time\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom scipy.ndimage.morphology import binary_dilation\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\n\n# MONAI imports for 3D U-Net and UNETR\nfrom monai.networks.nets import UNet, UNETR\nfrom monai.losses import DiceLoss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"files_dir = '/kaggle/input/lgg-mri-segmentation/lgg-mri-segmentation/kaggle_3m/'\nfile_paths = glob(f'{files_dir}/*/*[0-9].tif')\nprint(f\"Total files found: {len(file_paths)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_file_row(path):\n    \"\"\"Produces ID of a patient, image and mask filenames from a particular path\"\"\"\n    path_no_ext, ext = os.path.splitext(path)\n    filename = os.path.basename(path)\n    \n    patient_id = '_'.join(filename.split('_')[:3])\n    \n    return [patient_id, path, f'{path_no_ext}_mask{ext}']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filenames_df = pd.DataFrame((get_file_row(filename) for filename in file_paths), columns=['Patient', 'image_filename', 'mask_filename'])\nprint(f\"Total patient records: {len(filenames_df)}\")\nprint(filenames_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MriDataset(Dataset):\n    def __init__(self, df, transform=None):\n        super(MriDataset, self).__init__()\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx, raw=False):\n        row = self.df.iloc[idx]\n        img = cv2.imread(row['image_filename'], cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n        mask = cv2.imread(row['mask_filename'], cv2.IMREAD_GRAYSCALE)\n        \n        if raw:\n            return img, mask\n        \n        if self.transform:\n            augmented = self.transform(image=img, mask=mask)\n            image, mask = augmented['image'], augmented['mask']\n        \n        img = T.functional.to_tensor(img)  # Converts (H, W) to (1, H, W)\n        mask = mask // 255\n        mask = torch.Tensor(mask)\n        return img, mask","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MriDataset3D(Dataset):\n    def __init__(self, df, transform=None, max_depth=40):\n        super(MriDataset3D, self).__init__()\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.max_depth = max_depth\n        self.patients = self.df.groupby('Patient').groups\n        self.patient_ids = list(self.patients.keys())\n        \n    def __len__(self):\n        return len(self.patient_ids)\n        \n    def __getitem__(self, idx):\n        patient_id = self.patient_ids[idx]\n        indices = list(self.patients[patient_id])\n        \n        # Load all slices for a patient\n        images = []\n        masks = []\n        for i in indices:\n            row = self.df.loc[i]\n            img = cv2.imread(row['image_filename'], cv2.IMREAD_GRAYSCALE)\n            mask = cv2.imread(row['mask_filename'], cv2.IMREAD_GRAYSCALE)\n            \n            if img is None or mask is None:\n                continue\n                \n            images.append(img)\n            masks.append(mask // 255)\n        \n        if len(images) == 0:\n            raise ValueError(f\"No valid images found for patient {patient_id}\")\n        \n        # Stack to create 3D volume (D, H, W)\n        images = np.stack(images, axis=0)\n        masks = np.stack(masks, axis=0)\n        \n        # Pad or crop to fixed depth (max_depth)\n        current_depth = images.shape[0]\n        \n        if current_depth < self.max_depth:\n            # Pad with zeros at the end\n            pad_size = self.max_depth - current_depth\n            images = np.pad(images, ((0, pad_size), (0, 0), (0, 0)), mode='constant', constant_values=0)\n            masks = np.pad(masks, ((0, pad_size), (0, 0), (0, 0)), mode='constant', constant_values=0)\n        elif current_depth > self.max_depth:\n            # Crop to max_depth (take middle slices)\n            start = (current_depth - self.max_depth) // 2\n            images = images[start:start+self.max_depth]\n            masks = masks[start:start+self.max_depth]\n        \n        # Convert to (C, D, H, W) format for MONAI\n        images = torch.Tensor(images).unsqueeze(0).float()\n        masks = torch.Tensor(masks).unsqueeze(0).float()\n        \n        return images, masks","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, test_df = train_test_split(filenames_df, test_size=0.3, random_state=42)\ntest_df, valid_df = train_test_split(test_df, test_size=0.5, random_state=42)\n\nprint(f\"Training samples: {len(train_df)}\")\nprint(f\"Validation samples: {len(valid_df)}\")\nprint(f\"Test samples: {len(test_df)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2D datasets for 2D U-Net\ntransform = A.Compose([\n    A.RandomBrightnessContrast(p=0.3),\n    A.GaussNoise(p=0.2),\n    A.Rotate(limit=10, p=0.3),\n])\n\ntrain_dataset_2d = MriDataset(train_df, transform)\nvalid_dataset_2d = MriDataset(valid_df)\ntest_dataset_2d = MriDataset(test_df)\n\ntrain_loader_2d = DataLoader(train_dataset_2d, batch_size=16, shuffle=True)\nvalid_loader_2d = DataLoader(valid_dataset_2d, batch_size=16, shuffle=False)\ntest_loader_2d = DataLoader(test_dataset_2d, batch_size=1)\n\n# 3D datasets with padding to fixed size (40 slices)\ntrain_dataset_3d = MriDataset3D(train_df, max_depth=40)\nvalid_dataset_3d = MriDataset3D(valid_df, max_depth=40)\ntest_dataset_3d = MriDataset3D(test_df, max_depth=40)\n\ntrain_loader_3d = DataLoader(train_dataset_3d, batch_size=2, shuffle=True)\nvalid_loader_3d = DataLoader(valid_dataset_3d, batch_size=2, shuffle=False)\ntest_loader_3d = DataLoader(test_dataset_3d, batch_size=1)\n\nprint(\"2D Dataloaders created successfully!\")\nprint(\"3D Dataloaders created successfully (padded to 40 slices)!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EarlyStopping():\n   \n    def __init__(self, patience:int = 6, min_delta: float = 0, weights_path: str = 'weights.pt'):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.weights_path = weights_path\n\n    def __call__(self, val_loss: float, model: torch.nn.Module):\n        if self.best_loss - val_loss > self.min_delta:\n            self.best_loss = val_loss\n            torch.save(model.state_dict(), self.weights_path)\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n\n    def load_weights(self, model: torch.nn.Module):\n        return model.load_state_dict(torch.load(self.weights_path))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def iou_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):   \n    predictions = torch.where(predictions > 0.5, 1, 0)\n    labels = labels.byte()\n    \n    intersection = (predictions & labels).float().sum((1, 2))\n    union = (predictions | labels).float().sum((1, 2))\n    \n    iou = (intersection + e) / (union + e)\n    return iou\n\ndef dice_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n    predictions = torch.where(predictions > 0.5, 1, 0)\n    labels = labels.byte()\n    \n    intersection = (predictions & labels).float().sum((1, 2))\n    return ((2 * intersection) + e) / (predictions.float().sum((1, 2)) + labels.float().sum((1, 2)) + e)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def BCE_dice(output, target, alpha=0.01):\n    bce = torch.nn.functional.binary_cross_entropy(output, target)\n    soft_dice = 1 - dice_pytorch(output, target).mean()\n    return bce + alpha * soft_dice","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def training_loop(epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler, is_3d=False):\n    history = {'train_loss': [], 'val_loss': [], 'val_IoU': [], 'val_dice': []}\n    early_stopping = EarlyStopping(patience=7)\n    \n    for epoch in range(1, epochs + 1):\n        running_loss = 0\n        train_samples = 0\n        model.train()\n        \n        for data in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n            if is_3d:\n                # Handle list format from custom collate function\n                images_list, masks_list = data\n                for images, masks in zip(images_list, masks_list):\n                    # images and masks are already (C, D, H, W), add batch dimension\n                    images = images.unsqueeze(0).to(device)  # (1, C, D, H, W)\n                    masks = masks.unsqueeze(0).to(device)\n                    \n                    predictions = model(images)\n                    \n                    loss = loss_fn(predictions, masks)\n                    running_loss += loss.item()\n                    train_samples += 1\n                    \n                    loss.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n            else:\n                images, masks = data\n                images, masks = images.to(device), masks.to(device)\n                \n                predictions = model(images)\n                if len(predictions.shape) == 4:\n                    predictions = predictions.squeeze(1)\n                \n                loss = loss_fn(predictions, masks)\n                running_loss += loss.item() * images.size(0)\n                train_samples += images.size(0)\n                \n                loss.backward()\n                optimizer.step()\n                optimizer.zero_grad()\n        \n        # Validation\n        model.eval()\n        with torch.no_grad():\n            running_IoU = 0\n            running_dice = 0\n            running_valid_loss = 0\n            valid_samples = 0\n            \n            for data in valid_loader:\n                if is_3d:\n                    images_list, masks_list = data\n                    for images, masks in zip(images_list, masks_list):\n                        images = images.unsqueeze(0).to(device)\n                        masks = masks.unsqueeze(0).to(device)\n                        \n                        predictions = model(images)\n                        \n                        running_dice += dice_pytorch(predictions, masks).sum().item()\n                        running_IoU += iou_pytorch(predictions, masks).sum().item()\n                        loss = loss_fn(predictions, masks)\n                        running_valid_loss += loss.item()\n                        valid_samples += 1\n                else:\n                    images, masks = data\n                    images, masks = images.to(device), masks.to(device)\n                    \n                    predictions = model(images)\n                    if len(predictions.shape) == 4:\n                        predictions = predictions.squeeze(1)\n                    \n                    running_dice += dice_pytorch(predictions, masks).sum().item()\n                    running_IoU += iou_pytorch(predictions, masks).sum().item()\n                    loss = loss_fn(predictions, masks)\n                    running_valid_loss += loss.item() * images.size(0)\n                    valid_samples += images.size(0)\n        \n        train_loss = running_loss / max(1, train_samples)\n        val_loss = running_valid_loss / max(1, valid_samples)\n        val_dice = running_dice / max(1, valid_samples)\n        val_IoU = running_IoU / max(1, valid_samples)\n        \n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_IoU'].append(val_IoU)\n        history['val_dice'].append(val_dice)\n        \n        print(f'Epoch {epoch}/{epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | Val Dice: {val_dice:.6f} | Val IoU: {val_IoU:.6f}')\n        \n        lr_scheduler.step(val_loss)\n        if early_stopping(val_loss, model):\n            print(f\"Early stopping at epoch {epoch}\")\n            early_stopping.load_weights(model)\n            break\n    \n    model.eval()\n    return history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, test_loader, device, model_name, is_3d=False):\n    model.eval()\n    all_dice = []\n    all_iou = []\n    \n    with torch.no_grad():\n        for data in tqdm(test_loader, desc=f\"Evaluating {model_name}\"):\n            if is_3d:\n                images_list, masks_list = data\n                for images, masks in zip(images_list, masks_list):\n                    images = images.unsqueeze(0).to(device)\n                    masks = masks.unsqueeze(0).to(device)\n                    \n                    predictions = model(images)\n                    \n                    pred_binary = (predictions > 0.5).float()\n                    \n                    dice = dice_pytorch(pred_binary, masks).cpu().numpy()\n                    iou = iou_pytorch(pred_binary, masks).cpu().numpy()\n                    \n                    all_dice.extend(dice.flatten())\n                    all_iou.extend(iou.flatten())\n            else:\n                images, masks = data\n                images = images.to(device)\n                masks = masks.to(device)\n                \n                predictions = model(images)\n                \n                if predictions.shape != masks.shape:\n                    predictions = predictions.squeeze(1)\n                \n                pred_binary = (predictions > 0.5).float()\n                \n                dice = dice_pytorch(pred_binary, masks).cpu().numpy()\n                iou = iou_pytorch(pred_binary, masks).cpu().numpy()\n                \n                all_dice.extend(dice.flatten())\n                all_iou.extend(iou.flatten())\n    \n    return {\n        'model': model_name,\n        'dice': np.mean(all_dice),\n        'dice_std': np.std(all_dice),\n        'iou': np.mean(all_iou),\n        'iou_std': np.std(all_iou),\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"TRAINING MODEL 1: 2D U-Net (MONAI)\")\n\n\nmodel_unet_2d = UNet(\n    spatial_dims=2,\n    in_channels=1,\n    out_channels=1,\n    channels=(16, 32, 64, 128),\n    strides=(2, 2, 2),\n    num_res_units=2,\n)\nmodel_unet_2d.to(device)\n\noptimizer_2d = Adam(model_unet_2d.parameters(), lr=0.001)\nloss_fn_2d = torch.nn.BCEWithLogitsLoss()\nlr_scheduler_2d = ReduceLROnPlateau(optimizer=optimizer_2d, patience=3, factor=0.5)\n\nhistory_unet_2d = training_loop(20, model_unet_2d, train_loader_2d, valid_loader_2d, \n                                 optimizer_2d, loss_fn_2d, lr_scheduler_2d, is_3d=False)\n\nprint(\"\\n 2D U-Net Training Complete!\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"TRAINING MODEL 2: 3D U-Net (MONAI) - True 3D\")\n\n\nmodel_unet_3d = UNet(\n    spatial_dims=3,  # True 3D\n    in_channels=1,\n    out_channels=1,\n    channels=(16, 32, 64, 128),\n    strides=(2, 2, 2),\n    num_res_units=2,\n)\nmodel_unet_3d.to(device)\n\noptimizer_3d = Adam(model_unet_3d.parameters(), lr=0.001)\nloss_fn_3d = torch.nn.BCEWithLogitsLoss()\nlr_scheduler_3d = ReduceLROnPlateau(optimizer=optimizer_3d, patience=3, factor=0.5)\n\nhistory_unet_3d = training_loop(20, model_unet_3d, train_loader_3d, valid_loader_3d, \n                                 optimizer_3d, loss_fn_3d, lr_scheduler_3d, is_3d=False)\n\nprint(\"\\n✓ 3D U-Net Training Complete!\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"TRAINING MODEL 3: UNETR (Transformer-based, 3D)\")\n\n\nmodel_unetr_3d = UNETR(\n    in_channels=1,\n    out_channels=1,\n    img_size=(40, 256, 256),  # 3D volume size (D, H, W)\n    feature_size=16,\n    hidden_size=768,\n    mlp_dim=3072,\n    num_heads=12,\n    norm_name=\"instance\",\n    conv_block=True,\n    res_block=True,\n    spatial_dims=3,  # True 3D\n)\nmodel_unetr_3d.to(device)\n\noptimizer_unetr = Adam(model_unetr_3d.parameters(), lr=0.0005)\nloss_fn_unetr = torch.nn.BCEWithLogitsLoss()\nlr_scheduler_unetr = ReduceLROnPlateau(optimizer=optimizer_unetr, patience=3, factor=0.5)\n\n\nhistory_unetr_3d = training_loop(20, model_unetr_3d, train_loader_3d, valid_loader_3d, \n                                 optimizer_unetr, loss_fn_unetr, lr_scheduler_unetr, is_3d=False)\n\nprint(\"\\n✓ UNETR 3D Training Complete!\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=\" * 60)\nprint(\"TRAINING MODEL 4: nnU-Net \")\nprint(\"=\" * 60)\n\n\n# nnU-Net-like model: standard U-Net with aggressive augmentation\nmodel_nnunet = UNet(\n    spatial_dims=3,\n    in_channels=1,\n    out_channels=1,\n    channels=(32, 64, 128, 256),  # Deeper than standard\n    strides=(2, 2, 2),\n    num_res_units=2,\n    dropout=0.2,  # nnU-Net uses dropout\n)\nmodel_nnunet.to(device)\n\noptimizer_nnunet = Adam(model_nnunet.parameters(), lr=0.001, weight_decay=3e-5)  # nnU-Net uses weight decay\nloss_fn_nnunet = torch.nn.BCEWithLogitsLoss()\nlr_scheduler_nnunet = ReduceLROnPlateau(optimizer=optimizer_nnunet, patience=3, factor=0.5)\n\nhistory_nnunet = training_loop(20, model_nnunet, train_loader_3d, valid_loader_3d, \n                               optimizer_nnunet, loss_fn_nnunet, lr_scheduler_nnunet, is_3d=False)\n\nprint(\"\\nnnU-Net Training Complete!\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}